# ğŸ“MEMORIA â€” PDF Knowledge Chat (RAG)

Memoria is an AI learning assistant that lets users upload PDFs and ask questions based on the content inside them using Retrieval-Augmented Generation (RAG).

---

## ğŸš€ Features

* ğŸ“„ **Upload PDF**
* ğŸ” **Automatic text chunking + embeddings**
* ğŸ§  **Semantic search**
* ğŸ¤– **AI-generated answers from PDF context**
* ğŸ“š Powered by **Vector DB + LLM + Embedding model**

---

## ğŸ—ï¸ Tech Stack

| Purpose              | Tool          |
| -------------------- | ------------- |
| Embeddings           | Google AI     |
| Vector Database      | Qdrant        |
| PDF Reader           | PyMuPDF       |
| Backend API          | Flask         |
| Vector Search Client | Qdrant Client |
| Frontend             | HTML, CSS, JS |

---

## ğŸ“ Project Structure

```
EDU-BOT/
â”‚â”€â”€ app.py
â”‚â”€â”€ rag_engine.py
â”‚â”€â”€ embeddings.py
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ modules/
â”‚    â”œâ”€â”€ pdf_utils.py
â”‚    â”œâ”€â”€ qdrant_utils.py
â”‚    â””â”€â”€ chat_llm.py
â”‚â”€â”€ templates/
â”‚    â””â”€â”€ index.html
â”‚â”€â”€ static/
â”‚    â”œâ”€â”€ style.css
â”‚    â””â”€â”€ script.js
```

---

## âš™ï¸ Setup & Installation

1ï¸âƒ£ Clone the repository
2ï¸âƒ£ Create & activate virtual environment (Python 3.10+)

```
python -m venv venv
venv\Scripts\activate  (Windows)
source venv/bin/activate  (Mac/Linux)
```

3ï¸âƒ£ Install dependencies

```
pip install -r requirements.txt
```

4ï¸âƒ£ Add your API key as environment variable or `.env`

```
GEMINI_API_KEY=your_api_key_here
```

5ï¸âƒ£ Run the app

```
python app.py
```

The bot will start on **localhost**

---

## ğŸ’¬ API Usage

### Upload PDF

Endpoint:

```
POST /process_pdf
```

### Chat with EDU-BOT

Endpoint:

```
POST /chat
```

Example request:

```json
{
  "message": "What is pollution?"
}
```

---

## ğŸ§  How It Works (RAG Flow)

1. PDF text is extracted using Google AI embeddings
2. Text is split into chunks
3. Chunks are converted into vector embeddings using Qdrant semantic search
4. User questions are embedded and matched against stored vectors
5. Retrieved chunks are sent as context to Qdrant Client

---

## ğŸ” Important Notes

* Do **NOT push your real API key publicly**
* Add a `.gitignore` file including:

  ```
  .env
  venv/
  __pycache__/
  ```

---

## ğŸ“Œ Requirements

See the auto-generated `requirements.txt` file in the repo.

---

## ğŸŒŸ Future Enhancements

* Support for more formats (DOCX, PPTX)
* History-based chat memory
* Improved ranking + hybrid search

---

### â­ If you found this helpful, donâ€™t forget to give the repo a star on GitHub! ğŸ˜


